{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7603052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from os import path \n",
    "\n",
    "def record_audio(filename, duration=5, channels=1, rate=44100, chunk=1024):\n",
    "    \"\"\"Record audio from the microphone and save it to a WAV file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the output WAV file.\n",
    "        duration (int): The duration of the recording in seconds.\n",
    "        channels (int): The number of audio channels (1 for mono, 2 for stereo).\n",
    "        rate (int): The sample rate in Hz.\n",
    "        chunk (int): The number of frames per buffer.\n",
    "    \"\"\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Open the stream\n",
    "    stream = audio.open(format=pyaudio.paInt16,\n",
    "                        channels=channels,\n",
    "                        rate=rate,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=chunk)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    # Record for the specified duration\n",
    "    for _ in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618cf550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_audio(filename):\n",
    "    \"\"\"Analyze the recorded audio file.\n",
    "\n",
    "    Args:s\n",
    "        filename (str): The name of the WAV file to analyze.\n",
    "    \"\"\"\n",
    "    # Placeholder for analysis logic\n",
    "    print(f\"Analyzing {filename}...\")\n",
    "        \n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(filename) as source:\n",
    "        audio = r.record(source)\n",
    "        try:\n",
    "            data = r.recognize_google(audio, language=\"en-EN\")\n",
    "            print(data)\n",
    "        except Exception as e:\n",
    "            print(\"Please try again\")\n",
    "            print(e)\n",
    "    print(\"Analysis complete.\")\n",
    "    \n",
    "record_audio(\"output.wav\", duration=5, channels=1, rate=44100, chunk=1024)\n",
    "analyse_audio(\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c83c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the recognizer and microphone\n",
    "micro = sr.Microphone()\n",
    "r = sr.Recognizer()\n",
    "with micro as source:\n",
    "    print(\"Please say something...\")\n",
    "    audio = r.listen(source)\n",
    "    print(\"Recognizing...\")\n",
    "    try:\n",
    "        # Recognize speech using Google Web Speech API\n",
    "        text = r.recognize_google(audio, language=\"en-EN\")\n",
    "        print(\"You said: \" + text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I could not understand the audio.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results; {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d596d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vosk\n",
    "import pyaudio\n",
    "import json\n",
    "\n",
    "# Here I have downloaded this model to my PC, extracted the files \n",
    "# and saved it in local directory\n",
    "# Set the model path\n",
    "model_path = \"vosk-model-small-fr-0.22\"\n",
    "# Initialize the model with model-path\n",
    "model = vosk.Model(model_path)\n",
    "\n",
    "#if you don't want to download the model, just mention \"lang\" argument \n",
    "#in vosk.Model() and it will download the right  model, here the language is \n",
    "#US-English\n",
    "#model = vosk.Model(lang=\"en-us\")\n",
    "\n",
    "# Create a recognizer\n",
    "rec = vosk.KaldiRecognizer(model, 16000)\n",
    "# Open the microphone stream\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "                channels=1,\n",
    "                rate=16000,\n",
    "                input=True,\n",
    "                frames_per_buffer=8192)\n",
    "# Specify the path for the output text file\n",
    "output_file_path = \"recognized_text.txt\"\n",
    "    \n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    print(\"Listening for speech. Say 'fin' to stop.\")\n",
    "    # Start streaming and recognize speech\n",
    "    while True:\n",
    "        data = stream.read(4096)#read in chunks of 4096 bytes\n",
    "        if rec.AcceptWaveform(data):#accept waveform of input voice\n",
    "            # Parse the JSON result and get the recognized text\n",
    "            result = json.loads(rec.Result())\n",
    "            recognized_text = result['text']\n",
    "            \n",
    "            # Write recognized text to the file\n",
    "            output_file.write(recognized_text + \"\\n\")\n",
    "            print(recognized_text)\n",
    "            \n",
    "            # Check for the termination keyword\n",
    "            if \"fin\" in recognized_text.lower():\n",
    "                print(\"Termination keyword detected. Stopping...\")\n",
    "                break\n",
    "\n",
    "# Stop and close the stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "# Terminate the PyAudio object\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca96e9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3735928559"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0xdeadbeef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340e182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
